## 测试设计

### 自动触发

### 手动触发

1. 测试用例作为pod运行在其中
2. testcase记录测试用例状态
3. summary记录汇总状态
4. testcase和summary是两个crd

组件

1. sidecar容器：测试用例所在pod
2. operator：同步状态
   1. watch主资源（testcase对象），为每个testcase对象创建一个pod，pod中运行测试用例
   2. wathc次资源（pod对象），当测试用例运行完成，获取exitcode
      1. 向testcase对象中更新状态，并更新summary实例状态
      2. 向sidecar发送pod延迟退出周期

https://juejin.cn/post/7117220924843098143



部署流程：配置github action进行自动打包、进行自动化镜像打包、运行自动化测试、部署到k8s

测试流程：通过api接口，触发测试用例镜像pull，测试环境配置，测试脚本准备，将上述文件放到pod运行，使用oper

1. 我想开发基于k8s的自动化测试框架，每个测试用例作为一个pod运行，这些pod由TestCase对象创建，最终在testcase实例中记录pod的状态。测试用例运行时的pod是sider容器，同步状态使用operator，请问详细方案如何设计？

2. 我应该了解k8s、Docker和operator的哪些技术？

3. 如何使用使用k8s API来创建、更新和删除pod？

4. 什么是Kubernetes Sidecar容器？

5. kubernetes有哪几种部署方式？

6. venus我有测试用例，如何将这个测试用例打包为在pod中运行的镜像（dockerfile配置环境，python执行测试命令

   配置github action进行自动打包

## 部署设计

## Docker原理

### namesapce

1. 在 Linux 系统中创建线程的系统调用是 clone()，创建一个新进程时，就可以在参数中指定 CLONE_NEWPID 参数，比如：

```
int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 
```

这时，新创建的这个进程将会“看到”一个全新的进程空间，在这个进程空间里，它的 PID 是 1。之所以说“看到”，是因为这只是一个“障眼法”，在宿主机真实的进程空间里，这个进程的 PID 还是真实的数值，比如 100。

2. namespace还有Mount、UTS、IPC、Network和User。
   1. IPC：隔离System V IPC和POSIX消息队列
   2. Mount：隔离文件系统挂载点，每个容器能看到不同的文件系统层次结构。
   3. UTS：隔离主机名和域名

### 容器镜像

1. 容器镜像实际上是：rootfs（根文件系统）

2. 容器rootfs由三个部分组成：可读写层、Init层、只读层（我们可以通过docker commit和push指令，保存被修改过的可读写层，并上传到Docker Hub上，供其它人增强使用；且原先的只读层里的内容不会有任何改变）

3. docker镜像的设计中，引入了层（layer）的概念，也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。docker使用的rootfs往往由多个“层”组成：

   ```
   # 该镜像由5个layer组成，这5层就是5个增量rootfs
   # 在使用镜像时，Docker 会把这些增量联合挂载在一个统一的挂载点上
   docker image inspect ubuntu:latest
   ...
        "RootFS": {
         "Type": "layers",
         "Layers": [
           "sha256:f49017d4d5ce9c0f544c...",
           "sha256:8f2b771487e9d6354080...",
           "sha256:ccd4d61916aaa2159429...",
           "sha256:c01d74f99de40e097c73...",
           "sha256:268a067217b5fe78e000..."
         ]
       }
   ```

   

## Docker cli

```
docker run -it /bin/sh
-i: stdin, 为了能够在 tty 中输入信息，还需要同时开启 stdin（标准输入流）
-t: tty, Linux 给用户提供的一个常驻小程序，用于接收用户的标准输入，返回操作系统的标准输出
# 相当于在yaml中配置
  - name: shell
    image: busybox
    stdin: true
    tty: tru
```

```
# 共享宿net、IPC、PID
spec:
  hostNetwork: true
  hostIPC: true
  hostPID: true
```



## dockerfile

```dockerfile
FROM 909336740/nginx:v1.12.2
# 使用的用户
USER root
# env设置环境变了
ENV WWW /usr/share/nginx/html
ENV CONF /etc/nginx/conf.d
# run执行命令，修改时区
RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &&\ 
    echo 'Asia/Shanghai' >/etc/timezone
# workdir指定工作目录
WORKDIR $WWW
# add添加内容
ADD index.html $WWW/index.html
ADD demo.od.com.conf $CONF/demo.od.com.conf
# expore 暴露端口
EXPOSE 80
# 为启动的容器指定默认要运行的程序，程序结束时容器也会结束
CMD ["nginx","-g","daemon off;"]
```

demo.od.com.conf：

```
vi demo.od.com.conf
server {
   listen 80;
   server_name demo.od.com;

   root /usr/share/nginx/html;
}

# 下载并写入index.html
wget www.baidu.com -O index.html
docker build . -t 909336740/nginx:baidu
docker run --rm -p80:80 909336740/nginx:baidu
```

### dockerfile四种网络类型

- Bridge contauner（NAT） 桥接式网络模式(默认)
- None(Close) container 封闭式网络模式，不为容器配置网络
- Host(open) container 开放式网络模式，和宿主机共享网络
- Container(join) container 联合挂载式网络模式，和其他容器共享网络

## K8s

### pod

1. pod是k8s能被运行的最小单位

2. 一个pod里面可以有多个容器，所有容器共享一个network namespace，并且可以声明共享一个Volume

3. 一个pod里面运行多个容器，被称为SideCar模式

4. 调度、网络、存储、安全相关属性，基本上是Pod级别

   1. HostAliases：定义Pod的hosts文件内容

      1. ```
         spec:
           hostAliases:
           - ip: "10.1.2.3"
             hostnames:
             - "foo.remote"
             - "bar.remote"
         ```

   2. shareProcessNamespace=true：Pod容器里共享PID Namespace

      1. ```
         spec:
           shareProcessNamespace: true
         ```

      2. ```
         # 共享宿net、IPC、PID
         spec:
           hostNetwork: true
           hostIPC: true
           hostPID: true
         ```

   3. Container 

      1. **ImagePullPolicy**：定义了镜像拉取的策略

         - 默认是 Always，即每次创建 Pod 都重新拉取一次镜像。
         - 可以定义为 Never 或者 IfNotPresent，则意味着 Pod 永远不会主动拉取这个镜像，或者只在宿主机上不存在这个镜像时才拉取。

      2. Lifecycle Hooks：容器状态变化时触发的一系列hooks

         ```
         spec:
           containers:
           - name: lifecycle-demo-container
             image: nginx
             lifecycle:
               postStart:
                 exec:
                   command: ["/bin/sh", "-c", "echo Hello from the postStart handler > /usr/share/message"]
               preStop:
                 exec:
                   command: ["/usr/sbin/nginx","-s","quit"]
         ```

         

5. Pod状态

   1. **Pending**：这个状态意味着，Pod 的 YAML 文件已经提交给了 Kubernetes，API 对象已经被创建并保存在 Etcd 当中。但是，这个 Pod 里有些容器因为某种原因而不能被顺利创建。比如，调度不成功。
   2. **Running**：这个状态下，Pod 已经调度成功，跟一个具体的节点绑定。它包含的容器都已经创建成功，并且至少有一个正在运行中。
   3. **Succeeded**：这个状态意味着，Pod 里的所有容器都正常运行完毕，并且已经退出了。这种情况在运行一次性任务时最为常见。
   4. **Failed**：这个状态下，Pod 里至少有一个容器以不正常的状态（非 0 的返回码）退出。这个状态的出现，意味着你得想办法 Debug 这个容器的应用，比如查看 Pod 的 Events 和日志。
   5. **Unknown**：这是一个异常状态，意味着 Pod 的状态不能持续地被 kubelet 汇报给 kube-apiserver，这很有可能是主从节点（Master 和 Kubelet）间的通信出现了问题。

6. 水平扩展和滚动升级

   1. ReplicaSet：一个ReplicaSet对象，由副本数量和一个Pod模版组成，水平扩展/收缩就是修改副本数量。

      ```
      spec:
        # Pod副本数量是3
        replicas: 3
        selector:
          matchLabels:
            app: nginx
        template:
          metadata:
            labels:
              app: nginx
          spec:
            containers:
            - name: nginx
              image: nginx:1.7.9
      ```

7. RBAC：基于角色的权限控制

   ```
   kind: Role
   apiVersion: rbac.authorization.k8s.io/v1
   metadata:
     namespace: mynamespace
     name: example-role
   # rules定义权限规则
   rules:
   - apiGroups: [""]
     resources: ["pods"]
     verbs: ["get", "watch", "list"]
         ...
     # 相当于token
     secrets:
     - name: example-sa-token-vmfg6
   ```

8. Operator 工作原理

   利用k8s的自定义API资源（crd），来描述我们想要部署的“有状态应用”；然后在自定义控制器里，依据API对象的变化，完成部署运维等。

   ```
   # create etcd operator
   kubectl create -f example/deployment.yaml
   
   # pod进入running，自动创建一个crd
   kubectl get pods
   NAME                              READY     STATUS      RESTARTS   AGE
   etcd-operator-649dbdb5cb-bzfzp    1/1       Running     0          20s
    
   kubectl get crd
   NAME                                    CREATED AT
   etcdclusters.etcd.database.coreos.com   2018-09-18T11:42:55Z
   
   # 查看crd
   # 这个crd相当于告诉了k8s，如果有API group是etcd.database.coreos.com、API Kind是EtcdCluster的yaml被提交，k8s应该能识别。
   kubectl describe crd  etcdclusters.etcd.database.coreos.com
   Group:   etcd.database.coreos.com
     Names:
       Kind:       EtcdCluster
       List Kind:  EtcdClusterList
       Plural:     etcdclusters
       Short Names:
         etcd
       Singular:  etcdcluster
     Scope:       Namespaced
     Version:     v1beta2
   ```

   上述操作相当于在k8s里添加了一个叫EtcdCluster的自定义资源类型，Etcd Operator就是这个自定义资源的控制器。

   ```
   # 创建Etcd集群，只需编写EtcdCluster的yaml文件
   # example-etcd-cluster.yaml里描述是3节点Etcd
   $kubectl apply -f example/example-etcd-cluster.yaml
   
   $kubectl get pods
   NAME                            READY     STATUS    RESTARTS   AGE
   example-etcd-cluster-dp8nqtjznc   1/1       Running     0          1m
   example-etcd-cluster-mbzlg6sd56   1/1       Running     0          2m
   example-etcd-cluster-v6v6s6stxd   1/1       Running     0          2m
   ```

   

   

### Pod控制器

1. Pod控制器是Pod启动的一种模板，用来保证k8s里启动的pod按照预期运行
2. pod有多种控制器
   1. Deployment（常规发布）：Rolling update、Pause/resume、Canary deploy（金丝雀发布）、Rollback
   2. DaemonSet（Daemon作业）
   3. ReplicaSet（容器副本）
   4. StatefulSet（有状态任务）：Topology State、Storage State
   5. Job（一次性任务）
   6. Cronjob（定时任务）

### Name

1. k8s内部，使用“资源”来定义每一种逻辑概念，每种资源都应该有自己的名称。
2. “资源”有apiVersion、kind、metadata、spec、status等配置信息
3. “名称”通常定义在metadata中

### namespace

1. namespace用于隔离资源，使得对交付到k8s机群中的服务进行分类管理
2. k8s默认的namespace有default、kube-system、kube-public
3. 查询k8s中特定资源时，需要带上namespace

### Label

1. 一个labal可以对应多个资源，一个资源也可以有多个Label
2. 一个资源有多个Label，可以实现多维度管理
3. 标签组成：key=value
4. 与标签类似的是注解（annotation）

### Label选择器

1. 标签选择器目前有两个：基于等值关系（等于、不等于）和基于集合关系（属于、不属于、存在）
2. 许多资源支持内嵌标签选择器字段
   - matchLabels
   - matchExpressions

### Service

1. Service可以看作是一组提供相同服务的Pod对外访问接口
2. Service作用于哪些pod，通过Label选择器来定义

### ConfigMap

1. 应用配置管理

### Ingress

（七层服务发现）

1. Ingress是k8s集群在应用层对外暴露的接口

2. Service只能进行L4流量调度（ip+port）

3. Ingress可以调度不同的业务域

   ![1582188308711](https://github.com/ben1234560/k8s_PaaS/raw/master/assets/1582188308711.png)

### kubectl

k8s的命令行接口

### API Server

1. pod，service、RC的增删改查
2. 数据交换的枢纽

### Etcd

1. 包含在api server中，用于存储资源

### Controller Manager

1. 维护集群状态，如故障检测、自动扩展、滚动更新

### Scheduler

1. 资源调度、按照预定的调度策略将Pod调度到对应的机器

### kube-proxy

1. 负责为Service提供cluster内部的服务发现和负载均衡

### Kubelet

1. kubelet调用下层容器时，并不会直接调用Docker API，而是通过CRI（容器运行时接口）的gRPC接口来间接执行的。如果容器使用的是Docker，那么就会有一个叫dockershim的组件负责响应，这个组件会把CRI请求中的内容取出来，组装车Docker API发送给Docker Daemon。其他容器会有自己的插件。
2. CRI提供两组接口：
   1. 第一组，是 RuntimeService。它提供的接口，主要是跟容器相关的操作。比如，创建和启动容器、删除容器、执行 exec 命令等等。
   2. 第二组，则是 ImageService。它提供的接口，主要是容器镜像相关的操作，比如拉取镜像、删除镜像等等。



### k8s调度机制

#### 资源模型

```
spec:
  containers:
  - name: wp
  image: wordpress
  resources:
    requests:
      memory: "64Mi"
      cpu: "250m"
    limits:
      memory: "128Mi"
      cpu: "500m"
```

1. cpu是可压缩资源，资源不足时，pod只会“饥饿”，不会退出
2. 内存时不可压缩资源，资源不足时，Pod会因为OOM被内核kill
3. Pod 可以由多个 Container 组成，所以 CPU 和内存资源的限额，是要配置在每个 Container 的定义上的，而Pod整体资源配置，就由这些 Container 的配置值累加得到
4. requests：kube-scheduler只会按照requests计算
5. limits：设置Cgroup资源时，kubelet按照limit的值进行设置

#### QoS模型

- **Guaranteed**：Pod 里的每一个 Container 都同时设置了 requests 和 limits，并且 requests 和 limits 值相等的时候，这个 Pod 就属于 Guaranteed 
  - 建议将DaemonSet（亦或者类似的）的 Pod 都设置为 Guaranteed 的 QoS 类型，否则一旦被资源紧张被回收，又立即会在宿主机上重建出来，这样资源回收的动作就没有意义了
- **Burstable**：当 Pod 不满足 Guaranteed 的条件，但至少有一个 Container 设置了 requests。那么这个 Pod 就会被划分到 Burstable
- **BestEffort**：如果 Pod 既没有设置 requests，也没有设置 limits，那么它的 QoS 类别就是 BestEffort

#### cpuset

1. 在使用容器时，可以通过设置 cpuset 把容器绑定到某个 CPU 的核上，而不是像 cpushare 那样共享 CPU 的计算能力，这样CPU之间进行上下文切换的次数大大减少，容器里应用的性能会得到大幅提升。具体绑定到哪个cpu，由kubelet分配。

2. 实现方法：Pod 必须是 Guaranteed 的 QoS 类型

   

#### 调度策略

1. **Predicates**：开始调度一个pod时，k8s集群会同时启动16个goroutine，并发地计算所有Node的Predicates，最后返回可以运行这个pod的宿主机列表。
2. **Priorities**： 对得到的Node打分，范围0-10，得分最高的节点就是被Pod绑定的最佳节点。（一般是选择空闲cpu和内存最多的宿主机、资源分配最平衡的节点）
3. 

#### 调度器优先级



