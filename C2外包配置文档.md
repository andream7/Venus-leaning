# C2外包配置文档

[TOC]

版本：77bab4

插件：cluster_c2_plugin、gpuproxy、gpuproxy_worker



## gpuproxy

* 启动gpuproxy

```bash
./gpuproxy --url 0.0.0.0:18888 --log-level info run --db-dsn="mysql://root:admin123@192.168.200.119:3306/duan-gpuproxy-109" --disable-worker --fs-resource-path=/storage-nfs-4/theduan/fs-gpuproxy-25 --resource-type=fs

--url # 本地监听端口

-db-dsn # 数据库地址

--disable-worker # 禁用gpuproxy自己做C2

--resource-type=fs # C1使用文件方式存放

--fs-resource-path # C1文件存放的NFS挂载路径

--allow-type=0 # 可以做的任务类型，0 = C2
```

#### 使用说明：

* 当C2外包的机器需要跨访问时可以考虑db存储，否则建议fs存储
* gpuproxy会创建 resource_infos,seaql_migrations,tasks,worker_infos
* tasks表 state状态：1 init、 2 running、3 error、4 finished。
* 相关的命令

```bash
./gpuproxy tasks list
```



## venus-worker配置

```toml
[processors.limitation.concurrent]
c2 = 999

[[processors.c2]]
bin="/root/venus-cluster/dist/bin/cluster_c2_plugin"
args = ["run", "--gpuproxy-url", "http://192.168.200.25:18888"]
envs = {"RUST_LOG"="info"}
weight = 99
```

#### 使用说明：

* bin 填写cluster_c2_plugin路径
* args 中的 192.168.200.25:18888 为gpuproxy 的监听地址
* c2=999 表示c2能够并行的数量



## gpuproxy_worker

```bash
touch gpuproxy-worker.db # 创建一个空文件，用于记录 worker-id

FORCE_SECTOR_SIZE=34359738368 RUST_BACKTRACE=full RUST_LOG=info BELLMAN_LOAD_SHM=1 BELLMAN_USE_MAP_BUFFER=1 BELLMAN_CIRCUIT_N=1 BELLMAN_PROOF_N=1 CUDA_VISIBLE_DEVICES=1 ./gpuproxy_worker run --gpuproxy-url http://192.168.200.25:7654 --max-tasks=1 --allow-type=0  --resource-type=fs --fs-resource-path=/storage-nfs-4/theduan/fs-gpuproxy-25

--gpuproxy-url # gpuproxy地址

--max-tasks=1 # worker同时并行的任务量

--allow-type=0 # 指定C2
```

#### 使用说明：

* 一个worker绑定一张GPU，所以 max-tasks=1



## 注意事项：

* 尽量不要使用venus-worker本地跑C2，同时又用gpuproxy远程跑C2的情况
* 如果出现上述情况，请按照卡的数量分配权重，举例，本地1张跑C2，gpuproxy外包有55张C2：

```toml
[[processors.c2]]
bin="/root/venus-cluster/dist/bin/force-ext-processors"
args = ["processor", "c2", "--sector_size", "32GiB"]
concurrent = 1
envs = {RUST_BACKTRACE="full",RUST_LOG="trace"}
weight = 1  # 重量和卡数对应

[[processors.c2]]
bin="/root/venus-cluster/dist/bin/cluster_c2_plugin"
args = ["run", "--gpuproxy-url", "http://192.168.200.25:18888"]
envs = {"RUST_LOG"="info"}
weight = 55  # 重量和卡数对应
```

* weight表示任务分配的概率，同时配置本地和远程的情况下，本地为1，远程为55时表示远程分到的概率是 55/56 
* gpuproxy宕机的情况下需要手动恢复任务
* 数据库需要开启存储不足时自动截断
* error_msg字段存储报错信息
* 当任务出现报错时恢复操作：

```bash
./venus-worker worker -c venus-worker.toml list

>
#20: "/mnt/mount/theduan/3652/test21"; plan=sealer, sector_id=Some(s-t03652-163), paused=true, paused_elapsed=Some(785s), state=C1Done, last_err=Some("permanent: task 35189bdd-518f-50a7-bbfa-94fe22039c00 sector SectorId(163) error reason:Panic: recv prover: RecvError")

./venus-worker worker -c venus-worker.toml  resume -i 20
```

resume之后gpuproxy会重新下发指定的任务

* 当gpuproxy-worker.db被损坏时会影响任务的重置，和force-sealer中的worker-id逻辑类似
* 重置任务时，err_msg 不会被清除，只有等到这个任务被做完并且没有报错，err_msg才会被清除。
* 临时文件路径下的临时文件（37M左右）不会自动清除，避免空间被占满，需要一段时间后自己手动清除