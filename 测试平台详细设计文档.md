



[TOC]



# 问题

1. 总体运行流程

2. test_runner的运行逻辑（何时被触发，怎么去运行执行插件）

3. 新增一个job、task，如何被发现并调度运行？

4. 部署插件和测试插件分别都是怎么样被执行的

5. 插件的运行在k8s里面是怎么被执行的（可以引申出判断是否成功执行）

6. venus中的服务怎么被转变成k8s中的服务

7. 如何从k8s中读取运行日志并持久化

   

# 主要模块

```go
// 构建镜像相关
fx_opt.Override(fx_opt.NextInvoke(), func(ctx context.Context, builder *job.ImageBuilderMgr) {
  go builder.Start(ctx) //nolint
}),
// task相关
fx_opt.Override(fx_opt.NextInvoke(), func(ctx context.Context, taskMgr *job.TaskMgr) {
  go taskMgr.Start(ctx) //nolint
}),
// 不同类型的job构建、创建task、调度
fx_opt.Override(fx_opt.NextInvoke(), func(ctx context.Context, jobMgr job.IJobManager) {
  go jobMgr.Start(ctx) //nolint
}),
// TestRunner
fx_opt.Override(new(*job.TestRunnerDeployer), func() (*job.TestRunnerDeployer, error) {
  return job.NewTestRunnerDeployer(cfg.NameSpace, cfg.Mysql)
}),
```



# Job管理

```go
type IJobManager interface {
	Start(ctx context.Context) error
	InsertOrReplaceJob(ctx context.Context, job *models.Job) error
	ExecJobImmediately(ctx context.Context, jobId primitive.ObjectID) (primitive.ObjectID, error)
	NextNSchedule(ctx context.Context, jobId primitive.ObjectID, n int) ([]time.Time, error)
	StopJob(ctx context.Context, jobId primitive.ObjectID) error
	Stop(ctx context.Context) error
}

type IJob interface {
	ID() string
	Run(ctx context.Context) error
	RunImmediately(ctx context.Context) (primitive.ObjectID, error)
	NextNSchedule(ctx context.Context, n int) ([]time.Time, error)
	Stop(ctx context.Context) error
}

type JobManager struct {
	lk sync.Mutex

	cron         *cron.Cron
	taskRepo     repo.ITaskRepo
	jobRepo      repo.IJobRepo
	testflowRepo repo.ITestFlowRepo
	pluginRepo   repo.IPluginService

	runningJob   map[primitive.ObjectID]IJob    // 创建相应类型的Job实例时，会被添加到 runningJob 列表中
	pubsub       modules.WebHookPubsub
	githubClient *github.Client
}

```

## Start

函数`Start`是`JobManager`结构体的一个方法。它的作用是启动作业管理器，并根据存储在数据库中的作业配置开始执行相应的作业。

以下是`JobManager`结构体的`Start`方法的逻辑：

1. 首先，它从作业存储库中获取所有的作业列表。
2. 对于每个作业，它调用`InsertOrReplaceJob`方法将作业添加或替换到作业管理器中进行执行。
3. 如果添加或替换作业的过程中出现错误，它会记录错误并继续处理下一个作业。
4. 一旦所有作业都添加或替换完成，它调用`cron.Start()`方法启动Cron调度器。

总结起来，`Start`方法的逻辑是获取作业列表，将每个作业添加到作业管理器中进行执行，然后启动Cron调度器以按计划执行作业。

## InsertOrReplaceJob

`InsertOrReplaceJob`方法的作用：

1. **更新作业配置**：当作业的配置发生变化时，例如作业的调度时间、任务等发生了改变，需要将最新的配置应用到作业管理器中。通过调用`InsertOrReplaceJob`方法，可以更新作业管理器中相应作业的配置，以便使用最新的配置进行执行。
2. **停止旧作业**：·`InsertOrReplaceJob`方法会先停止旧的作业实例，然后再添加新的作业实例。这样可以确保作业管理器中只有最新的作业在运行，避免旧的作业实例继续执行。
3. **处理作业类型变化**：通过调用`InsertOrReplaceJob`方法，可以根据作业的类型（比如cron类型）创建相应的作业实例，并将其添加到`JobManager`中进行执行。

## ExecJobImmediately

1. 检查是否存在具有给定作业 ID 在runningJob列表中；
2. 如果存在对应的Job，它调用该作业的 `RunImmediately` 方法来**立即执行**作业，并返回执行结果；
3. 如果不存在对应的运行中作业，返回一个错误。

## StopJob

1. 停止runningJob列表中的job并从列表中移除

## IJob的三种实现

### CronJob

- 定时任务触发Job

```go
type CronJob struct {
	job      models.Job   // job结构体
	cron     *cron.Cron   // cron调度器
	taskRepo repo.ITaskRepo  // task表
	jobRepo  repo.IJobRepo   // job表

	cronId *cron.EntryID // 存储 Cronjob 在 Cron 调度器中的调度项 ID，是每个Job的唯一标识
}
```

1. `Run` 方法：
   - 根据作业的 Cron 表达式，向 Cron 调度器添加一个函数，这个函数的作用是调用 `RunImmediately` 方法来立即运行job，生成一个`entryId`，`entryId` 是一个指向 `cronJob.cron` 添加的定时任务的标识符的指针。通过将其赋值给 `cronJob.cronId` 字段，可以在其他方法中引用该定时任务。一般一次性创建三个cronJob，代表未来三个执行计划。
   - 将 `entryId` 存储在 `cronJob.cronId` 中。
2. `RunImmediately` 方法：
   - 首先会增加job的执行计数，使用 `jobRepo.IncExecCount` 方法将job的执行计数加一。
   - 然后创建一个新的任务（`Task`）并保存到数据库的task表中，保存的任务包含了job的名称、执行计数等信息。
   - 返回保存任务后生成的task ID。
3. `NextNSchedule` 方法：
   - 获取 Cronjob的`cronJob.cronId` 对应的调度项（`Entry`）。
   - 获取下一次作业执行的时间，将其存储在 `nextN` 切片中，如果需要获取多个未来的执行时间，则根据调度项的时间表计算并添加到 `nextN` 切片中。
4. `Stop` 方法：
   - 根据 Cronjob的调度器 ID，使用 `cron.Remove` 方法从 Cron 调度器中移除该job的`cronJob.cronId`。



相关日志：

```shell
// 创建3个CronJob（Run方法）
2023-09-21T16:33:01.602+0800	INFO	cron_job	job/cron_job.go:76	add job 遥遥领先 entry 1	{"job": "ObjectID(\"6503ef8b368ecc80ade957b0\")", "testflow": "ObjectID(\"6503ec40368ecc80ade957ac\")"}
2023-09-21T16:33:01.602+0800	INFO	cron_job	job/cron_job.go:76	add job test2 entry 2	{"job": "ObjectID(\"6502d96a63e11fa21e84b789\")", "testflow": "ObjectID(\"65029d4885264591fa741ff1\")"}
2023-09-21T16:33:01.602+0800	INFO	cron_job	job/cron_job.go:76	add job 继续领先 entry 3	{"job": "ObjectID(\"6504028a368ecc80ade957b9\")", "testflow": "ObjectID(\"650401fa368ecc80ade957b8\")"}

2023-09-21T16:33:01.602+0800	INFO	cron_job	job/cron_log.go:22	start

// JobManager的Start方法，表示启动作业管理器
2023-09-21T16:33:01.602+0800	INFO	builder	job/job.go:123	start cron job worker

// cron log日志，表示已经进入调度
2023-09-21T16:33:01.602+0800	INFO	cron_job	job/cron_log.go:22	schedule	{"now": "2023-09-21T16:33:01.602+0800", "entry": 1, "next": "2024-01-01T01:01:00.000+0800"}
2023-09-21T16:33:01.602+0800	INFO	cron_job	job/cron_log.go:22	schedule	{"now": "2023-09-21T16:33:01.602+0800", "entry": 2, "next": "2024-01-01T01:01:00.000+0800"}
2023-09-21T16:33:01.603+0800	INFO	cron_job	job/cron_log.go:22	schedule	{"now": "2023-09-21T16:33:01.602+0800", "entry": 3, "next": "2024-01-01T01:01:00.000+0800"}
```

### PRMergedJob

- Pull Request事件触发Job

```go
type PRMergedJob struct {
	jobId        primitive.ObjectID
	taskRepo     repo.ITaskRepo
	jobRepo      repo.IJobRepo
	testflowRepo repo.ITestFlowRepo

	githubClient *github.Client         // 链接
	pubsub       modules.WebHookPubsub   // 用于发布和订阅事件和webHook

	logger *zap.SugaredLogger
}
```

1. `Run` 方法：
   - `Run` 方法启动一个 `goroutine`，并在其中创建一个循环，从 `WebHook` 接收事件。Webhook被触发的条件是有新的Pull Request被合并。
   - 循环中的每个event都被转换为 `github.PullRequestEvent` 类型，并传递给 `execTag` 方法进行处理。

2. `ExecTag` 方法：

   - `execTag` 方法首先从数据库中获取与当前 `PRMergedJob` 实例关联的 `Job`。
   - 获取包含pull request的代码仓库全名。

   - 然后，遍历 `Job` 的 `PRMergedEventMatches` 字段，逐个匹配。
   - 对于每个匹配项，检查事件的仓库全名是否包含在匹配项的仓库字段中。
   - 对于匹配的项，使用正则表达式分别匹配源分支和目标分支。
   - 如果源分支和目标分支都匹配成功，则调用 `generateTaskFromJob` 方法生成任务。

3. `generateTaskFromJob` 方法的执行逻辑是：

   - 首先增加 `Job` 的执行计数，并根据计数生成任务的名称。

   - 然后，它调用 `taskRepo.Save` 方法将任务保存到数据库中。

4. `RunImmediately` 方法：

   - 创建一个立刻执行的task

### TagCreateJob

- 创建Tag事件触发Job

```go
type TagCreateJob struct {
	jobId        primitive.ObjectID
	taskRepo     repo.ITaskRepo
	jobRepo      repo.IJobRepo
	testflowRepo repo.ITestFlowRepo

	pluginRepo   repo.IPluginService      //插件服务
	githubClient *github.Client
	pubsub       modules.WebHookPubsub

	logger *zap.SugaredLogger
}
```

1. `Run` 方法：
   - 启动一个 goroutine，用于监听发布事件（ReleaseEvent）。
   - 当有发布事件发生时，调用 `execTag` 方法。

2. `ExecTag` 方法：

   - 获取task和相关的testflow信息，解析测试流程的Graph。
   - 获取release事件中的Repo Name和Tag Name。
   - 针对作业中的每个标签创建事件匹配规则，检查仓库名称是否匹配，并匹配标签引用与规则中的标签模式。
   - 如果匹配成功，则记录符合规则的标签版本。
   - 保存更新后的作业信息。
   - 调用 `generateTaskFromJob` 方法生成与作业相关的任务。

3. `generateTaskFromJob` 方法的执行逻辑是：

   - 首先增加 `Job` 的执行计数，并根据计数生成任务的名称。

   - 创建一个新的任务（Task）对象，填充相关字段，如名称、关联的作业 ID、测试流程 ID、状态等。
   - 调用 `taskRepo.Save` 方法将新的任务对象保存到数据库中，并返回任务的唯一标识符。

4. `RunImmediately` 方法：

   - 创建一个立刻执行的task

# 构建镜像

## Builder Worker Provider 

1. `CreateBuildWorker`方法
   - 用于创建BuildWorker，并配置构建工作器所需的各种依赖项和配置信息。

## Builder Manager

```
type ImageBuilderMgr struct {
	pluginRepo repo.IPluginService
	workerCfgs []config.BuildWorkerConfig
	taskCh     chan *BuildTask
	provider   IBuilderWorkerProvider
}
```

1. `Start` 方法：
   - 调用`BuildWorkerProvider`的`CreateBuildWorker`方法，创建多个`BuildWorker`实例。
   - 创建的`BuildWorker`会以并发的方式启动。
2. `BuildTestFlowEnv`方法：
   - 对于每个Deploy插件，Builder Manager 从数据库的plugins表中获取插件信息。
   - 如果插件可构建（存在BuildScript），则创建一个构建任务。
   - 构建任务被发送到任务通道后，BuildWorker会从任务通道中接收任务并执行构建操作。
   - 构建工作器完成构建后，将构建结果（BuildResult）发送到对应构建任务的结果通道中。
   - Builder Manager 通过接收构建结果，将构建成功的插件名称和版本添加到 versionMap 中。
   - 返回 versionMap，其中包含每个成功构建的插件Name和Version的映射关系。

## BuildWorker

作用：用于执行插件的构建任务

1. `Start`方法

   1. 接收构建任务：Builder Worker 在 Start 方法中通过接收一个任务通道（taskCh），等待构建任务的到来。

   2. 执行构建任务：一旦有构建任务到达，Builder Worker 就会执行 do 方法来处理构建任务。具体执行流程如下：

      a. 获取插件信息： 通过数据库的plugins表，根据构建任务的插件name和version，获取相应的插件信息。

      b. 创建 ImageBuilder：如果当前插件所在仓库对应的ImageBuilder不存在，则创建一个新的 ImageBuilder。ImageBuilder 用于构建镜像的实例。

      c. 获取代码提交版本：调用 `ImageBuilder.FetchCommit` 方法，获取代码的Version。

      d. 检查镜像是否存在：通过调用 `docker.CheckImageExist` 方法，检查镜像是否已存在。

      e. 构建镜像：如果镜像不存在，则调用 `ImageBuilder.Build` 方法开始执行构建操作，使用插件的构建脚本对代码进行构建。构建完成后，会生成一个新的镜像版本。

      f. 返回结果：构建完成后，Builder Worker 将构建结果（包括生成的镜像版本）通过构建任务的结果通道（Result）返回。

## ImageBuilder

```
type IIMageBuilder interface {
	FetchCommit(ctx context.Context, commit string) (string, error)
	Build(ctx context.Context, script, commit string) error
}
```

1. `FetchCommit`方法：用于获取指定提交的哈希值
   - 调用`updateRepo`方法更新代码仓库。
   - 如果`commit`参数为空，则获取当前代码仓库的HEAD提交的哈希值，并将其作为结果返回。
   - 尝试解析`commit`参数为提交的哈希值。如果解析成功，则将其作为结果返回。
   - 如果解析失败，尝试解析`commit`参数为分支或标签。如果解析成功，则获取对应的远程分支的哈希值，并将其作为结果返回。
   - 如果以上步骤都失败，则返回错误。
2. `Build`方法：构建镜像
   - 调用`updateRepo`方法更新代码仓库。
   - 根据传入的`commit`参数获取对应的提交的哈希值。
   - 使用获取到的提交的哈希值，切换到对应的提交。
   - 调用`scriptRunner`的`ExecScript`方法执行构建脚本，构建镜像。
3. `updateRepo`方法：更新代码仓库
   - 检查当前代码仓库是否存在。如果不存在，则进行初始化，包括创建新的代码仓库或克隆远程代码仓库到本地。
   - 如果代码仓库已存在，则执行以下操作：
     - 检查当前分支是否为默认分支（通常是主分支，如`master`或`main`）。如果不是默认分支，则切换到默认分支。
     - 执行`git fetch`命令，从远程仓库获取最新的分支、标签和提交信息。
     - 执行`git pull`命令，将本地代码库与远程代码库进行合并，以确保本地代码库是最新的。

## 相关日志

```shell
// ImageBuilder的`updateRepo`方法：更新代码仓库
2023-09-21T16:31:43.153+0800	DEBUG	builder	job/image_builder.go:368	update repo /root/brightbird/buildspace/droplet branch(master) to latest


// Build Worker，获取代码提交版本
2023-09-21T16:31:44.284+0800	INFO	builder	job/image_builder.go:210	get repo droplet-client commit f49ad932b880f2f6bc42158f8668dc46e6d98602 success	{"worker": "/root/brightbird/buildspace"}
2023-09-21T16:31:44.289+0800	INFO	builder	job/image_builder.go:210	get repo venus-daemon commit b78d8c6e807f20a2fe5b266ad4878690bfb91da4 success	{"worker": "/root/brightbird/buildspace3"}
2023-09-21T16:31:44.438+0800	INFO	builder	job/image_builder.go:210	get repo droplet commit f49ad932b880f2f6bc42158f8668dc46e6d98602 success	{"worker": "/root/brightbird/buildspace2"}

// Build Worker，判断对应版本的镜像是否存在，从而决定是否构建镜像，这里发现镜像已存在，无需构建
2023-09-21T16:31:44.519+0800	DEBUG	builder	job/image_builder.go:226	node droplet-client (f49ad932b880f2f6bc42158f8668dc46e6d98602) have build image before skip	{"worker": "/root/brightbird/buildspace"}
2023-09-21T16:31:44.686+0800	DEBUG	builder	job/image_builder.go:226	node droplet (f49ad932b880f2f6bc42158f8668dc46e6d98602) have build image before skip	{"worker": "/root/brightbird/buildspace2"}
2023-09-21T16:31:45.059+0800	DEBUG	builder	job/image_builder.go:226	node venus-daemon (b78d8c6e807f20a2fe5b266ad4878690bfb91da4) have build image before skip	{"worker": "/root/brightbird/buildspace3"}
```

# Task管理

1. `Start`方法
   - 创建一个 `time.Ticker` 对象 `tm`，每隔一分钟触发一次。进入一个无限循环，循环中的逻辑如下：
   - 从数据库中获取待处理的作业列表 `jobs`，遍历Jobs。
   - 尝试移除已完成的`testRunner`，检查正在运行的任务的状态。
   - 对于每个正在运行的任务，检查`testRunner`的状态，如果发现失败或者重试次数超过5次，删除并检查下一个。
   - 获取处于初始化状态的任务列表 `initTasks`。
   - 对于每个初始化状态的任务，调用 `RunOneTask` 方法运行任务。
2. `RunOneTask`方法：用于运行单个任务
   - 调用 `Process` 函数处理任务，并获取一个 Pod。
   - 如果在处理过程中出现错误，则将task标记为失败并存到数据库；如果成功，将task的状态标记为`Success`。
3. `StopOneTask`方法：用于停止单个任务
   - 从数据库的task表获取task相关信息，清理与task相关的测试资源。
   - 将task的状态更新为`Error`并保存到数据库。
4. `Process`方法：负责处理任务
   - 从数据库获取testflow和job的相关信息。
   - 将测试流程的图形从YAML格式反序列化为 `models.Graph` 结构体。
   - 调用`ImageBuilder.BuildTestFlowEnv`为测试流程的环境构建一个镜像。
   - 使用相关数据更新任务的testflow和提交映射。
   - 创建一个默认的全局参数映射 `defaultGlobal`，并设置默认的日志级别，合并自定义属性到 `defaultGlobal` 中，将测试流程的全局属性和作业的全局属性合并到 `defaultGlobal` 中，对 `defaultGlobal` 进行序列化和转义。
   - 调用`TestRunner.ApplyRunner`来运行测试流程。

# TestRunnerDeployer

1. `ApplyRunner`方法

   - 将传入的`testrunner-deployment-template.yaml`解析为`corev1.Pod`对象，该对象描述了要创建的test-runner的配置。

   - 从`corev1.Pod`对象中获取Pod的名称。
   - 使用Kubernetes客户端的`CoreV1().Pods`方法获取Pod的API客户端，调用Pod的API客户端的`Create`方法创建Pod。
   - 如果创建成功，返回创建的Pod对象。

3. `testrunner-deployment-template.yaml`配置文件：

   ```
   apiVersion: v1
   kind: Pod
   metadata:
     namespace: {{.NameSpace}}
     name: test-runner-{{.TestID}}
     labels:
       app: venus-testrunner-pod
       apptype: testrunner
       testid: {{.TestID}}
   spec:
     restartPolicy: OnFailure
     initContainers:
     containers:
       - name: venus-testrunner
         image: "{{if gt (len .Registry) 0}}{{.Registry}}/{{end}}filvenus/testrunner:zsk"
         imagePullPolicy: Always
         args: [{{.Args}}]
         env:
           - name: PRODUCTION
             value: "true"
         volumeMounts:
           - mountPath: /shared-dir
             name: shared-dir-v
             subPath: {{.NameSpace}}
     volumes:
       - name: shared-dir-v
         persistentVolumeClaim:
           claimName: shared-dir
   ```

   4. 相关日志

   ```shell
   // ApplyRunner方法创建Pod，获取yaml配置文件
   2023-09-21T16:31:45.062+0800	INFO	builder	job/runner_deployer.go:69	scriptRunner config apiVersion: v1
   kind: Pod
   metadata:
     namespace: zsk
     name: test-runner-93e5b83a
     labels:
       app: venus-testrunner-pod
       apptype: testrunner
       testid: 93e5b83a
   spec:
     restartPolicy: OnFailure
     initContainers:
     containers:
       - name: venus-testrunner
         image: "192.168.200.175/filvenus/testrunner:zsk"
         imagePullPolicy: Always
         args: ["--plugins=/shared-dir/plugins", "--namespace=zsk",  "--dbName=zsk", "--mongoUrl=mongodb://192.168.200.175:27017", "--mysql=root:Aa123456@(192.168.200.175:3306)/%s?parseTime=true&loc=Local&charset=utf8mb4&collation=utf8mb4_unicode_ci&readTimeout=10s&writeTimeout=10s", "--registry=192.168.200.175", "--taskId=650bff3028b05664413e65c7", --globalParams, '{"logLevel":"DEBUG"}'
   ]
         env:
           - name: PRODUCTION
             value: "true"
         volumeMounts:
           - mountPath: /shared-dir
             name: shared-dir-v
             subPath: zsk
     volumes:
       - name: shared-dir-v
         persistentVolumeClaim:
           claimName: shared-dir
   
   // test-runner创建开始
   2023-09-21T16:31:45.063+0800	INFO	builder	job/runner_deployer.go:77	Creating scriptRunner test-runner-93e5b83a ...
   
   // test-runner创建成功
   2023-09-21T16:31:45.073+0800	INFO	builder	job/runner_deployer.go:82	Created scriptRunner test-runner-93e5b83a.
   ```

   

   